# WordCount
***
맵리듀스의 처리 단계를 워드카운트 예제로 확인해 보겠습니다. 이 워드카운트 예제는 하둡의 맵리듀스 튜토리얼의 워드 카운트 예제를 이용합니다. 워드카운트는 입력된 파일의 문자수를 세는 프로그램입니다. 워드 카운트의 작업 단계는 다음과 같습니다.

![wc](https://i.stack.imgur.com/199Q1.png)

워드 카운트의 전체 소스코드는 다음과 같습니다. 다음 코드는 세부분으로 나눌 수 있습니다. 매퍼를 구현한 TokenizerMapper, 리듀서를 구현한 IntSumReducer 잡을 설정하는 main() 함수입니다.
```
import java.io.IOException;
import java.util.StringTokenizer;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WordCount {

    // 맵
    public static class TokenizerMapper extends Mapper<Object, Text, Text, IntWritable> {

        private final static IntWritable one = new IntWritable(1);
        private Text word = new Text();

        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {

            // 입력된 한라인(value)을 공백을 기준으로 분할하여 
            // context 객체를 이용하여 임시파일로 저장

            StringTokenizer itr = new StringTokenizer(value.toString());
            while (itr.hasMoreTokens()) {
                word.set(itr.nextToken());
                context.write(word, one);
            }
        }
    }

    // 리듀스 
    public static class IntSumReducer extends Reducer<Text, IntWritable, Text, IntWritable> {
        private IntWritable result = new IntWritable();

        // 키(문자)별로 전달된 문자의 개수를 모두 더하여 출력  
        public void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {
            int sum = 0;
            for (IntWritable val : values) {
                sum += val.get();
            }
            result.set(sum);
            context.write(key, result);
        }
    }

    public static void main(String[] args) throws Exception {
        // Job 객체를 이용하여 하둡 작업을 실행 
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, "word count");
        job.setJarByClass(WordCount.class);
        job.setMapperClass(TokenizerMapper.class);
        job.setCombinerClass(IntSumReducer.class);
        job.setReducerClass(IntSumReducer.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);
        FileInputFormat.addInputPath(job, new Path(args[0]));  // 입력 파일위치
        FileOutputFormat.setOutputPath(job, new Path(args[1]));  // 출력 파일위치 
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}
```

# 실행
***
하둡 맵리듀스의 실행은 jar 파일을 이용합니다. 워드카운트 예제를 빌드하여 jar 파일로 생성하고 실행합니다.

# 작업준비
***
먼저 입력으로 사용할 파일을 생성하고 HDFS에 복사합니다. 입력 파일의 형식은 다음과 같습니다.

```
$ cat word.txt 
Deer Bear River
Car Car River
Deer Car Bear

# 작업 파일 복사 
$ hadoop fs -put ./word.txt /user/word/input/
```
# 실행
***
실행은 다음과 같이 `hadoop jar` 명령을 이용합니다. 작업 대상 jar파일과 클래스 명을 명시하고 작업 파라미터인 입력 위치와 출력위치를 전달합니다.

```
$ hadoop jar Mapreduce.jar sdk.WordCount /user/word/input /user/word/output
```
# 작업결과
***
작업 결과는 part 파일로 생성됩니다. _SUCCESS 는 작업의 성공 여부를 알려주는 파일입니다. 맵리듀스 프레임워크에서 자체적으로 생성하는 파일입니다.

```
# 실행결과 확인 
$ hadoop fs -ls /user/word/output/
Found 8 items
-rw-r--r--   2 hadoop hadoop          0 2019-02-21 05:39 /user/word/output/_SUCCESS
-rw-r--r--   2 hadoop hadoop          0 2019-02-21 05:39 /user/word/output/part-r-00000
-rw-r--r--   2 hadoop hadoop          0 2019-02-21 05:39 /user/word/output/part-r-00001
-rw-r--r--   2 hadoop hadoop          7 2019-02-21 05:39 /user/word/output/part-r-00002
-rw-r--r--   2 hadoop hadoop          0 2019-02-21 05:39 /user/word/output/part-r-00003
-rw-r--r--   2 hadoop hadoop          0 2019-02-21 05:39 /user/word/output/part-r-00004
-rw-r--r--   2 hadoop hadoop          0 2019-02-21 05:39 /user/word/output/part-r-00005
-rw-r--r--   2 hadoop hadoop         21 2019-02-21 05:39 /user/word/output/part-r-00006

# 파일 내용 확인 
$ hadoop fs -cat /user/word/output/part*
Deer    2
Bear    2
Car 3
River   2
```

# WordCount 처리단계
***
# 입력
***
워드카운트는 파일로 데이터를 입력 받습니다. 파일 위치를 파라미터로 전달하면 FileInputFormat을 이용해서 데이터를 읽습니다. FileInputFormat은 지정한 위치의 파일을 라인단위로 읽어서 맵에 전달합니다.

```
FileInputFormat.addInputPath(job, new Path(args[0]));
```

# Map
***
맵은 전달받은 <키, 밸류>에서 밸류 데이터를 공백 단위로 분할하여 문자수를 세어줍니다. 맵에서 데이터를 정리하지 않습니다. 같은 문자가 있어도 합계를 내지 않고 하나씩 처리합니다.

```
[입력, <버퍼번호, 라인>]
1, Deer Bear River
16, Car Car River
30, Deer Car Bear

[출력, <문자, 1>]
Dear 1
Bear 1
River 1
Car 1
Car 1
River 1
Dear 1
Car 1
Bear 1
```
map 함수의 key로 들어오는 값이 버퍼 번호이고, value 로 들어오는 값이 라인이 됩니다. 이 value를 공백을 기준으로 잘라서 문자 단위로 파일이 쓰게 됩니다.

```
public void map(Object key, Text value, Context context) throws IOException, InterruptedException {

            // 입력된 한라인(value)을 공백을 기준으로 분할하여 
            // context 객체를 이용하여 임시파일로 저장
            StringTokenizer itr = new StringTokenizer(value.toString());
            while (itr.hasMoreTokens()) {
                word.set(itr.nextToken());
                context.write(word, one);
            }
        }
```

# Combiner
***
컴바이너는 잡에 설정 합니다. 컴바이너는 설정해도 되고, 설정하지 않아도 동작에 영향을 주지 않습니다.
```
job.setCombinerClass(IntSumReducer.class);
```
컴바이너를 설정하면 로컬에서 리듀서 작업을 처리합니다. 다음 처럼 리듀서로 전달하는 결과가 줄어들기 때문에 네트워크 자원의 사용량을 줄일 수 있습니다.
```
[입력, <문자, 1>]
Dear 1
Bear 1
River 1
Car 1
Car 1
River 1
Dear 1
Car 1
Bear 1

[출력, <문자, List(1)>]
Dear List(1, 1)
Bear List(1, 1)
Car List(1, 1, 1)
River List(1, 1)
```
# 파티셔너, 셔플, 소트
***
워드카운트 예제에서 파티셔너, 셔플, 소트 단계는 따로 설정하지 않습니다. 맵리듀스 프레임워크의 기본 단계를 이용하여 맵의 결과는 리듀스의 입력으로 전달됩니다.
```
[맵의 결과]
Dear 1
Bear 1
River 1
Car 1
Car 1
River 1

[리듀서의 입력]
Dear List(1, 1)
Bear List(1, 1)
Car List(1, 1, 1)
River List(1, 1)
```

# 리듀서
***
리듀서는 키별로 전달된 등장횟수를 모두 더하여 전체 등장회수를 생성합니다.
```
[입력, <문자, List(1)>]
Dear List(1, 1)
Bear List(1, 1)
Car List(1, 1, 1)
River List(1, 1)

[출력, <문자, 횟수>]
Deer    2
Bear    2
Car 3
River   2
```
문자가 key로 들어오고, 등장 횟수가 Iterable 형태로 전달됩니다. 이 값들을 모두 더하여 결과를 출력합니다.
```
public void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {
            int sum = 0;
            for (IntWritable val : values) {
                sum += val.get();
            }
            result.set(sum);
            context.write(key, result);
        }
```

# 출력
***
지정한 위치에 파일로 출력합니다. 출력 파일의 개수는 리듀서의 개수와 일치합니다.
```
FileOutputFormat.setOutputPath(job, new Path(args[1]));
```











